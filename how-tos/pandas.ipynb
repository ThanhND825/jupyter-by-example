{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Tips & Tricks\n",
    "\n",
    "This notebook presents various tricks to manipulate your data, which are typically non-obvious to a novice in Pandas and data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import time\n",
    "from IPython.display import HTML, clear_output, display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def text_plain(obj):\n",
    "    \"\"\"Display text-only version in output cell.\"\"\"\n",
    "    display(obj, include='text/plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple CSV Files\n",
    "\n",
    "This shows how to create a single dataframe from multiple files that share the same structure (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11 ../data/commits1.tsv\n",
      "  12 ../data/commits2.tsv\n",
      "  23 total\n",
      "♯ 21\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = '../data/commits*.tsv'\n",
    "df = pd.concat([pd.read_csv(x, sep='\\t', parse_dates=['Date']) for x in glob.glob(files)], \n",
    "               ignore_index=True)\n",
    "\n",
    "!wc -l {files}\n",
    "print('♯', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.Author.unique()), len(pd.unique(df.Author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Dataframes\n",
    "\n",
    "Looking at the contents and metadata of your dataframes is quite important, to better understand the data they represent and then successfully transform it into the results you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data dimensions (rows, cols)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHA                                      object\n",
       "Author                                   object\n",
       "Date       datetime64[ns, pytz.FixedOffset(60)]\n",
       "Message                                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at a sample, it is often useful to transpose the data, especially when you have many columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           0                            1\n",
       "SHA                                  8fe0ea9                      9de3457\n",
       "Author                              jhermann                     jhermann\n",
       "Date               2019-02-16 06:04:19+01:00    2019-02-16 05:57:50+01:00\n",
       "Message  :link: Python Data Science Handbook  add requirements for Binder"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(df.head(2).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then there is `describe` with some core statistics about the dataframe…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            SHA    Author                       Date                Message\n",
       "count        21        21                         21                     21\n",
       "unique       21         2                         21                     21\n",
       "top     714a749  jhermann  2019-02-15 21:23:05+01:00  pandas: future topics\n",
       "freq          1        20                          1                      1\n",
       "first       NaN       NaN  2019-02-11 16:06:17+01:00                    NaN\n",
       "last        NaN       NaN  2019-02-16 06:04:19+01:00                    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… and `info` with more technical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      "SHA        21 non-null object\n",
      "Author     21 non-null object\n",
      "Date       21 non-null datetime64[ns, pytz.FixedOffset(60)]\n",
      "Message    21 non-null object\n",
      "dtypes: datetime64[ns, pytz.FixedOffset(60)](1), object(3)\n",
      "memory usage: 752.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Results\n",
    "### Writing Spreadsheet Files\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Rows\n",
    "\n",
    "You can use [loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) in combination with a `bool` array to select a subset of rows. That array is conveniently created by applying conditions to columns.\n",
    "\n",
    "The first example uses regex matching…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Date                                   Message\n",
       "7  2019-02-15 17:17:30+01:00               Altair: use non-random data\n",
       "8  2019-02-15 16:58:26+01:00  Altair: Publishing Charts with nbconvert\n",
       "10 2019-02-15 10:40:04+01:00                      Altair setup details"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(df.loc[df.Message.str.match('altair', case=False)]\n",
    "             .reindex(['Date', 'Message'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is using simple comparison operators, e.g. `!=` like here…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Date         Message\n",
       "20 2019-02-11 16:06:17+01:00  Initial commit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(df.loc[df.Author != 'jhermann']\n",
    "             .reindex(['Date', 'Message'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the condition creates a `bool` array, that then is taken by `loc[…]` to select the matching rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, True]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.Author.iloc[-5:] != 'jhermann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding or Replacing Columns\n",
    "Changing the values of a column or adding a whole new one can be done by actual assignment or by calling `assign`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ♯: 4 vs. 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                       Date                              Message  Words\n",
       "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook      5\n",
       "1 2019-02-16 05:57:50+01:00          add requirements for Binder      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "morecols = df.assign(Words=df.Message.str.split().apply(len))\n",
    "print('Column ♯:', len(df.columns), 'vs.', len(morecols.columns))\n",
    "text_plain(morecols.head(2).iloc[:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using assigment is inplace and changes the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Date                              Message  Words  Zero\n",
       "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook      5     0\n",
       "1 2019-02-16 05:57:50+01:00          add requirements for Binder      4     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "morecols['Zero'] = 0\n",
    "text_plain(morecols.head(2).iloc[:, -4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "This one's easy, just call [rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html). Columns can be specified in various formats, like a mapping from old to new. Renaming can also be done inplace, the default is to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Date                                 Text  Words  Zero\n",
       "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook      5     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(morecols.rename(columns=dict(Message='Text')).head(1).iloc[:, -4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rename all columns, just `zip` the existing names with the new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         0         1                         2  \\\n",
       "0  8fe0ea9  jhermann 2019-02-16 06:04:19+01:00   \n",
       "\n",
       "                                     3  4  5  \n",
       "0  :link: Python Data Science Handbook  5  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numcols = morecols.rename(\n",
    "    columns=dict(zip(morecols.columns, \n",
    "                     range(len(morecols.columns)))))\n",
    "text_plain(numcols.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rename according to some logic, like a regex substitution or similar, provide a mapper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       SHA    AUTHOR                      DATE  \\\n",
       "0  8fe0ea9  jhermann 2019-02-16 06:04:19+01:00   \n",
       "\n",
       "                               MESSAGE  WORDS  ZERO  \n",
       "0  :link: Python Data Science Handbook      5     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(morecols.rename(mapper=str.upper, axis=1).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Columns\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Date                              Message\n",
       "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_plain(df[['Date', 'Message']].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Manipulation\n",
    "\n",
    "The new `Day` column is just the first word out of the `Date` column. By splitting with `expand=True` two columns are created (instead of one column with tuples), so we can select the first column only and add this to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Date                              Message         Day\n",
       "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook  2019-02-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.assign(Day=df.Date.astype(str).str.split(n=1, expand=True)[0])\n",
    "text_plain(df.head(1).iloc[:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Date` is a `datetime64` column, we can also use the [DatetimeProperties](http://pandas.pydata.org/pandas-docs/version/0.15.0/api.html#datetimelike-properties) accessor for day extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Date                              Message         Day\n",
       "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook  2019-02-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.assign(Day=df.Date.dt.date)\n",
    "text_plain(df.head(1).iloc[:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "To visualize data in bar or other magnitude charts, you have to count subsets of your raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/pandas-barh.png?1552233818.4997842\"></img>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits_per_day = df.Day.value_counts().to_frame().sort_index()\n",
    "_ = commits_per_day.plot.barh(legend=False, figsize=(5, 2))\n",
    "\n",
    "chart_img = 'img/pandas-barh.png'\n",
    "plt.savefig(chart_img)\n",
    "clear_output()\n",
    "HTML('<img src=\\\"{}?{}\\\"></img>'.format(chart_img, time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Grouping values by one or more columns and then applying an operation to fold those values into a single scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Code\n",
       "Letter      \n",
       "P         80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letters = list(\"Pandas\")\n",
    "codes = pd.DataFrame(dict(Letter=letters, Code=list(map(ord, letters))))\n",
    "codes = codes.groupby('Letter').aggregate(np.sum)\n",
    "text_plain(codes.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `reset_index` moves the grouping column(s) from the index to ordinary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Letter  Code\n",
       "0      P    80\n",
       "1      a   194\n",
       "2      d   100\n",
       "3      n   110\n",
       "4      s   115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codes = codes.reset_index()\n",
    "text_plain(codes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
